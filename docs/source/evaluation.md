(evaluation)=

# Evaluating TREs against SATRE

This section details the method for evaluating a TRE against the SATRE specification.

This document also includes two example evaluations for {ref}`The Alan Turing Institute's Data Safe Haven <evaluation_alan_turing_institute>` and {ref}`The University of Dundee/HIC's TREEHOOSE <evaluation_dundee_hic>`.
We hope that these examples will help you to write your own evaluation.

(why_evaluate)=

## Why should I evaluate my institution's TRE?



## Method

You should score your TRE against each statement in the SATRE specification.
The scoring system is:

0 (Not met)
: The TRE does not meet this requirement

1 (Sufficient)
: The TRE meets this requirement met but there is substantial scope for improvement

2 (Satisfied)
: The TRE meets this requirement met but there may still be scope for improvement

**0** means you have failed to meet the requirement.
A score of **1** or above means you have met the requirement.
Although both **1** and **2** indicate a TRE meets the requirement, they indicate different levels of possible improvement.

An evaluation may simply give your TRE scores for each statement.
We recommend a more detailed evaluation, which includes a score, a justification and, where applicable, suggestions for improvement.

The example evaluations are detailed, including the supporting text as well as scores.

### Combining scores

The scores for each statement can be easily combined at the capability, pillar or overall level.
If all the **Mandatory** statements in a capability are met, either at level **1** or level **2**, then the capability is met.
If all capabilities in a pillar are met then the pillar is met.
If all pillars are met then the SATRE specification is met.

## Evaluation spreadsheet

You can use this {download}`spreadsheet <../build/satrecsv/satre.xlsx>` as a template for your evaluation.
